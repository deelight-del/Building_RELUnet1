{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddab85f",
   "metadata": {},
   "source": [
    "## Building a Rectified Learner Unit (RELU) to be used on Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e039e56",
   "metadata": {},
   "source": [
    "After following Fastai course and on module 3, I want to use a jupyter notebook to build a Rectified Learner Unit which is a kind of basic building block for that is used in neural nets that is used and employed in deep learning to make machine learning algorithms.\n",
    "\n",
    "The goal of this notebook is to explain and build the RELU while using the titanic training dataset obtained from kaggle as a test for this framework. This is built on some libraries like numpy, pytorch and some other frameworks used along the line and will be referenced as appropriate. Interesting to note here is that most of the libraries needed for this to function have all been imported from the one line `from fastai.basics import *` below which is as seen in the cell block below.\n",
    "\n",
    "RELUs are simple linear equation algorithms that uses Gradient Descent for optimizations. And that is what we are going to be doing exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7721977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from fastai.basics import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c14c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import our dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3f936c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Survived       0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.198653\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.771044\n",
       "Embarked       0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform some necessary cleaning, transformation and feature engineering\n",
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6664b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete cabin and PassengerId in dataset, drop null values of Age and Embarked columns\n",
    "df.drop(columns = [\"PassengerId\", \"Cabin\"], inplace = True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f02dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete cabin colums -- High Cardinality\n",
    "df.drop(columns = \"Name\", inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95e32cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete cabin colums  ---High cardinality\n",
    "df.drop(columns = \"Ticket\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2736515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0.0\n",
       "Pclass      0.0\n",
       "Sex         0.0\n",
       "Age         0.0\n",
       "SibSp       0.0\n",
       "Parch       0.0\n",
       "Fare        0.0\n",
       "Embarked    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "456c1642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d477ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add dummy feature that will be used in the RELU matrx multiplication function\n",
    "dummy_list = [1] * len(df)\n",
    "df[\"dummy\"] = dummy_list\n",
    "df['dummy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "266426ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  dummy\n",
       "0         0       3    male  22.0      1      0   7.2500        S      1\n",
       "1         1       1  female  38.0      1      0  71.2833        C      1\n",
       "2         1       3  female  26.0      0      0   7.9250        S      1\n",
       "3         1       1  female  35.0      1      0  53.1000        S      1\n",
       "4         0       3    male  35.0      0      0   8.0500        S      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c07cb1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"Survived\", axis = 1).shape   ##Shape of dataset without target that is going into transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d0872",
   "metadata": {},
   "source": [
    "Perform transformations such as standard scaler, and OneHotEncoding on categorical data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a90ec50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    1\n",
       "2    3\n",
       "3    1\n",
       "4    3\n",
       "Name: Pclass, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First convert PClass to an object feature\n",
    "\n",
    "df[\"Pclass\"] = df[\"Pclass\"].astype(str)\n",
    "df[\"Pclass\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fddf685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00281295, -0.59032605, -0.56653751, ..., -0.47261792,\n",
       "        -0.20232566,  1.        ],\n",
       "       [-0.99719495,  1.69397911, -0.56653751, ...,  2.11587407,\n",
       "        -0.20232566,  1.        ],\n",
       "       [ 1.00281295, -0.59032605, -0.56653751, ..., -0.47261792,\n",
       "        -0.20232566,  1.        ],\n",
       "       ...,\n",
       "       [-0.99719495,  1.69397911, -0.56653751, ..., -0.47261792,\n",
       "        -0.20232566,  1.        ],\n",
       "       [-0.99719495,  1.69397911, -0.56653751, ...,  2.11587407,\n",
       "        -0.20232566,  1.        ],\n",
       "       [ 1.00281295, -0.59032605, -0.56653751, ..., -0.47261792,\n",
       "         4.94252683,  1.        ]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"Survived\"\n",
    "Xt = df.drop(columns = [\"dummy\", target]) #Initiate Xt, transformed that will be used for matrix multiplication,\n",
    "                                          #Drop dummy and target column, to avoid target and dummy getting transformed  \n",
    "\n",
    "transform_pipe = make_pipeline(OneHotEncoder(), #Transformation initialized in a pipeline\n",
    "                          StandardScaler())\n",
    "\n",
    "Xt = transform_pipe.fit_transform(Xt)         #Transformer piplien object made and called on the Xt dataset\n",
    "\n",
    "dm_array = np.array(df[\"dummy\"])[:, None]     #Create dummy array of the dummy column to be added back to the Xt to 2D\n",
    "\n",
    "Xt = np.concatenate([Xt, dm_array], axis = 1)  #Concatenate dummy array into Xt\n",
    "Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "424e962b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 13)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a11d5c",
   "metadata": {},
   "source": [
    "From the above we see that we arrived at a dataset of 712 rows and 13 columns, which is because of the category encoders, Lets us see below the columns that have been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27711cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_1', 'Sex_2', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_1', 'Embarked_2', 'Embarked_3']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(transform_pipe.named_steps[\"onehotencoder\"].get_feature_names())\n",
    "print(len(transform_pipe.named_steps[\"onehotencoder\"].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c2ed9af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(712, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(df[target])[:, None]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f451d",
   "metadata": {},
   "source": [
    "Since the dummy variable was not part of the features that went through the transformation pipeline, thus the length of the features generated by the transformer pipeline was 12 columns and plus 1(dummy feature) added manually by concatenation to make the final 13 columns that was generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6ae2c",
   "metadata": {},
   "source": [
    "The next step is to instantiate a tensor of random values that will be the paramenters of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "023c4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate random seed\n",
    "np.random.seed(42)\n",
    "parameters = (np.random.random(13*1) - 0.5)[:, None]\n",
    "parameters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eaf3bc",
   "metadata": {},
   "source": [
    "Parameters that have been generated are random and are not responsive to a loss function yet until we put it into a tensor that does that. So the next step will involve using tensors and not numpy arrays to adjust the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "94dfa0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert parameters to tensor object\n",
    "parameters_t = torch.tensor(parameters)\n",
    "#Also convert y array into tensor\n",
    "y_t = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f913b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First let us define our loss function that our tensor of parameters will be adjusted by\n",
    "def mae(acts, preds): return (torch.abs(preds - acts)).mean()\n",
    "\n",
    "#Also define function that makes prediction using tensor parameters and clipping values of y (A RELU function)\n",
    "def tensor_prediction(params):\n",
    "    result = torch.matmul(torch.tensor(Xt), params)\n",
    "    return torch.clip(result, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b5686c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6577, dtype=torch.float64)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us calculate the mae from the first random initial parameters that was generated\n",
    "\n",
    "mae(y_t, tensor_prediction(parameters_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed298f2c",
   "metadata": {},
   "source": [
    "From the above we see the mean absolute error being so high, so next we will initiate the adjustable torch parameters that will be adjusted based on gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a987626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1255],\n",
       "        [ 0.4507],\n",
       "        [ 0.2320],\n",
       "        [ 0.0987],\n",
       "        [-0.3440],\n",
       "        [-0.3440],\n",
       "        [-0.4419],\n",
       "        [ 0.3662],\n",
       "        [ 0.1011],\n",
       "        [ 0.2081],\n",
       "        [-0.4794],\n",
       "        [ 0.4699],\n",
       "        [ 0.3324]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initiate requires_grad with the torch method for the parameters\n",
    "parameters_t.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9bc77024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function mae_loss that calculates the mae_loss with only parameter given\n",
    "def mae_loss(params):\n",
    "    return mae(y_t, tensor_prediction(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "bf2992c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6577, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Put the mae_loss function into a variable that calculates the loss based on the adjustable parameters\n",
    "#Test on the initial parameters seleced to see function is running properly --It should return\n",
    "#same loss as above --0.6577\n",
    "\n",
    "loss = mae_loss(parameters_t)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "2a645b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0474],\n",
       "        [-0.0481],\n",
       "        [-0.0061],\n",
       "        [ 0.3478],\n",
       "        [-0.3478],\n",
       "        [-0.0189],\n",
       "        [-0.1106],\n",
       "        [-0.0123],\n",
       "        [-0.0739],\n",
       "        [ 0.0887],\n",
       "        [-0.1591],\n",
       "        [ 0.1265],\n",
       "        [ 0.3750]], dtype=torch.float64)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrive the gradient of each parameters\n",
    "#each parameter has a partial derivative with respect to the loss function chosen\n",
    "#This is what is printed out as their gradients below\n",
    "loss.backward()   #This method initiates the grad attribute that will be needed to checked\n",
    "parameters_t.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9c046",
   "metadata": {},
   "source": [
    "From the gradients displayed from the information above, we see that some parameters do have a negative gradient and with increase in their values, they would tend to get to the minimum values and lower the loss. The opposite is true for the positve gradients. Because in order to reduce the loss, we need a minima (gradient) values (close to zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "058ec698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0; loss=0.66\n",
      "step=1; loss=0.65\n",
      "step=2; loss=0.64\n",
      "step=3; loss=0.62\n",
      "step=4; loss=0.60\n",
      "step=5; loss=0.57\n",
      "step=6; loss=0.54\n",
      "step=7; loss=0.52\n",
      "step=8; loss=0.49\n",
      "step=9; loss=0.46\n",
      "step=10; loss=0.44\n",
      "step=11; loss=0.42\n",
      "step=12; loss=0.40\n",
      "step=13; loss=0.38\n",
      "step=14; loss=0.36\n",
      "step=15; loss=0.34\n",
      "step=16; loss=0.33\n",
      "step=17; loss=0.32\n",
      "step=18; loss=0.31\n",
      "step=19; loss=0.31\n"
     ]
    }
   ],
   "source": [
    "#Using gradient descent to perform the paramaters adjustment\n",
    "for i in range(20):\n",
    "    loss = mae_loss(parameters_t)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): parameters_t -= parameters_t.grad*0.01\n",
    "    print(f'step={i}; loss={loss:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc5b77",
   "metadata": {},
   "source": [
    "The parameters have been adjusted up to an optimal value (based on the range of values we chose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "00acbe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1569],\n",
       "        [ 0.4731],\n",
       "        [ 0.2458],\n",
       "        [-0.4885],\n",
       "        [ 0.2432],\n",
       "        [-0.2807],\n",
       "        [-0.2634],\n",
       "        [ 0.2648],\n",
       "        [ 0.1585],\n",
       "        [ 0.0437],\n",
       "        [-0.1444],\n",
       "        [ 0.1555],\n",
       "        [-0.3334]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With this change above, let us see the final parameters\n",
    "parameters_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6fa2a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.79\n"
     ]
    }
   ],
   "source": [
    "#Let us use this value to make predictions and check the accuracy_score of our prediction\n",
    "y_pred = tensor_prediction(parameters_t)\n",
    "y_pred = [1 if pred>0.5 else 0 for pred in y_pred]\n",
    "print(f\"Accuracy score: {accuracy_score(y_t, y_pred).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cfa49d",
   "metadata": {},
   "source": [
    "This above is valid and used for creating a one layer RELUnet. In order to create a double layer RELUnet function, some tweaks with the ready made materials made from above will be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "d20ba848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4247],\n",
      "        [ 0.3773],\n",
      "        [-0.2421],\n",
      "        [ 0.1600],\n",
      "        [ 0.3172],\n",
      "        [ 0.0552],\n",
      "        [ 0.0297],\n",
      "        [-0.2581],\n",
      "        [-0.4069],\n",
      "        [ 0.3972],\n",
      "        [ 0.4004],\n",
      "        [ 0.1331],\n",
      "        [-0.1610]], dtype=torch.float64) tensor([[-0.1508],\n",
      "        [ 0.2260],\n",
      "        [ 0.3971],\n",
      "        [ 0.3871],\n",
      "        [ 0.2799],\n",
      "        [ 0.1420],\n",
      "        [-0.4159],\n",
      "        [-0.3384],\n",
      "        [ 0.3986],\n",
      "        [ 0.1064],\n",
      "        [-0.4908],\n",
      "        [-0.3985],\n",
      "        [ 0.1635]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Create param1 and param2 which will adjustable parameters\n",
    "\n",
    "param1 = torch.tensor((np.random.random(13*1) - 0.5)[:, None])\n",
    "param2 = torch.tensor((np.random.random(13*1) - 0.5)[:, None])\n",
    "#param1.requires_grad_()\n",
    "#param2.requires_grad_()\n",
    "print(param1, param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "0101713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4247, -0.1508],\n",
       "        [ 0.3773,  0.2260],\n",
       "        [-0.2421,  0.3971],\n",
       "        [ 0.1600,  0.3871],\n",
       "        [ 0.3172,  0.2799],\n",
       "        [ 0.0552,  0.1420],\n",
       "        [ 0.0297, -0.4159],\n",
       "        [-0.2581, -0.3384],\n",
       "        [-0.4069,  0.3986],\n",
       "        [ 0.3972,  0.1064],\n",
       "        [ 0.4004, -0.4908],\n",
       "        [ 0.1331, -0.3985],\n",
       "        [-0.1610,  0.1635]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_params = torch.hstack([param1, param2])\n",
    "grand_params.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "913e7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double RELU function that takes advantage of the matrix multpilication\n",
    "def grand_pred(params):\n",
    "    result = torch.matmul(torch.tensor(Xt), params)\n",
    "    result = torch.clip(result, 0.)\n",
    "    result = result[:,0] + result[:,1]\n",
    "    return result[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "afb4b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define mae_loss\n",
    "def grand_mae_loss(params):\n",
    "    return mae(y_t, grand_pred(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "064b716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6797, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grand_loss = grand_mae_loss(grand_params)\n",
    "grand_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "1d883347",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "555d75db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1567, -0.0579],\n",
       "        [-0.0238,  0.0227],\n",
       "        [-0.1583,  0.0442],\n",
       "        [ 0.2289,  0.2249],\n",
       "        [-0.2289, -0.2249],\n",
       "        [ 0.1052,  0.1994],\n",
       "        [-0.1001, -0.1933],\n",
       "        [-0.1548, -0.2496],\n",
       "        [-0.1172, -0.0379],\n",
       "        [ 0.1797,  0.1875],\n",
       "        [-0.1866, -0.1608],\n",
       "        [-0.0132, -0.0813],\n",
       "        [ 0.2795,  0.4017]], dtype=torch.float64)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the gradient of each \n",
    "grand_params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "95548538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=0; loss=0.68\n",
      "step=1; loss=0.66\n",
      "step=2; loss=0.64\n",
      "step=3; loss=0.60\n",
      "step=4; loss=0.56\n",
      "step=5; loss=0.52\n",
      "step=6; loss=0.47\n",
      "step=7; loss=0.43\n",
      "step=8; loss=0.41\n",
      "step=9; loss=0.39\n",
      "step=10; loss=0.37\n",
      "step=11; loss=0.35\n",
      "step=12; loss=0.34\n",
      "step=13; loss=0.32\n",
      "step=14; loss=0.31\n",
      "step=15; loss=0.30\n",
      "step=16; loss=0.30\n",
      "step=17; loss=0.30\n",
      "step=18; loss=0.30\n",
      "step=19; loss=0.30\n"
     ]
    }
   ],
   "source": [
    "#Take loop through the gadient descent\n",
    "for i in range(20):\n",
    "    grand_loss = grand_mae_loss(grand_params)\n",
    "    grand_loss.backward()\n",
    "    with torch.no_grad(): grand_params -= grand_params.grad*0.01\n",
    "    print(f'step={i}; loss={grand_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d1154fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1929,  0.0450],\n",
       "        [ 0.3915,  0.1051],\n",
       "        [ 0.0137,  0.2922],\n",
       "        [-0.0961,  0.0514],\n",
       "        [ 0.5733,  0.6156],\n",
       "        [-0.0907, -0.2422],\n",
       "        [ 0.1265, -0.0912],\n",
       "        [-0.0277,  0.0952],\n",
       "        [-0.2602,  0.3273],\n",
       "        [ 0.1795, -0.1568],\n",
       "        [ 0.6057, -0.2741],\n",
       "        [ 0.1905, -0.2667],\n",
       "        [-0.5955, -0.4883]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the final grand parameter\n",
    "grand_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "26fbf4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Let us use this value to make predictions and check the accuracy_score of our prediction\n",
    "y_pred = grand_pred(grand_params)\n",
    "y_pred = [1 if pred>0.5 else 0 for pred in y_pred]\n",
    "print(f\"Accuracy score: {accuracy_score(y_t, y_pred).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "45b89385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple naive model wil have an accuracy of 0.5955\n"
     ]
    }
   ],
   "source": [
    "naive_model=round(df[\"Survived\"].value_counts(normalize=True).max(), 4)\n",
    "print(f\"A simple naive model wil have an accuracy of {naive_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b747b2",
   "metadata": {},
   "source": [
    "From this, we see that the RELUnet that we made does far well than a simlple and naive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "45948023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying both model on the test set\n",
    "#first define wrangle function\n",
    "\n",
    "def wrangle(filepath):\n",
    "    \n",
    "    #Read in filepath\n",
    "    data = pd.read_csv(filepath)\n",
    "    #Obtain dataindex\n",
    "    data_index = data[\"PassengerId\"]\n",
    "    \n",
    "    #Drop the following stated columns\n",
    "    data.drop(columns = [\"PassengerId\", \"Cabin\", \"Name\", \"Ticket\"], inplace = True)\n",
    "    \n",
    "    #Fill missing values\n",
    "    data[\"Age\"].fillna(data[\"Age\"].mode()[0], inplace=True)\n",
    "    data[\"Fare\"].fillna(data[\"Fare\"].mean(), inplace=True)\n",
    "    #Convert the Pclass column to string type\n",
    "    data[\"Pclass\"] = data[\"Pclass\"].astype(str)\n",
    "    \n",
    "    #create dummy\n",
    "    dummy = [1] * len(data)\n",
    "    \n",
    "    #Add transformation to the dataset\n",
    "    train_trans = transform_pipe.fit_transform(data)        \n",
    "    \n",
    "    #Concatenate dummy array into train_trans\n",
    "    dummy_array = np.array(dummy)[:, None]     \n",
    "    train_trans = np.concatenate([train_trans, dummy_array], axis = 1)  \n",
    "    return train_trans, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "7f7e3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train, idx = wrangle(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "baaca1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 13)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "3fca7af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "b0403f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_data(data, model_parameters):\n",
    "    result = torch.matmul(torch.tensor(data), model_parameters)\n",
    "    result = torch.clip(result, 0.)\n",
    "    if model_parameters.shape[1] > 1:\n",
    "        result = result[:,0] + result[:,1]\n",
    "        return result[:,None]\n",
    "    return result[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "e15c3533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "RELU1_pred = pred_data(test_train, parameters_t)\n",
    "RELU1_pred = [1 if pred>0.5 else 0 for pred in RELU1_pred]\n",
    "print(RELU1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "b05958a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "RELU2_pred = pred_data(test_train, grand_params)\n",
    "RELU2_pred = [1 if pred>0.5 else 0 for pred in RELU2_pred]\n",
    "print(RELU2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "5b74312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(RELU2_pred, index=idx).rename(\"prediction\").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "448eed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pd.Series(RELU1_pred, index=idx).rename(\"prediction\").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "6a410628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "fe577305",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.rename(columns={\"index\": \"PassengerId\", \"prediction\":\"Survived\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "bac0198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1.to_csv(\"RELU20221prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e18ac",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "- The whole process can be more flexible than many hardcodcoding done in this notebook. I only did this as a form of practical learning and trying my hands on what I was taught. A suitable way to go about this might be encapsulate it all as a class\n",
    "\n",
    "- The model built does not take into consideration of setting aside a validation dataset upon which the loss function is compared and subsequently adjusting the parameters. As a result, the model is very prone to overfitting.\n",
    "\n",
    "- A double RELUnet will possibly take more time(epochs) to train than a single RELUnet, thus on a more refined model construction, the double RELUnet model should do better than the single net model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e819f",
   "metadata": {},
   "source": [
    "## Image of entry into the titanic dataset competition with self built RELU network\n",
    "\n",
    "![image](Images/kaggle.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
