{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fddab85f",
   "metadata": {},
   "source": [
    "## Building a Rectified Learner Unit (RELU) to be used on Titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e039e56",
   "metadata": {},
   "source": [
    "After following Fastai course and on module 3, I want to use a jupyter notebook to build a Rectified Learner Unit which is a kind of basic building block for that is used in neural nets that is used and employed in deep learning to make machine learning algorithms.\n",
    "\n",
    "The goal of this notebook is to explain and build the RELU while using the titanic training dataset obtained from kaggle as a test for this framework. This is built on some libraries like numpy, pytorch and some other frameworks used along the line and will be referenced as appropriate. Interesting to note here is that most of the libraries needed for this to function have all been imported from the one line `from fastai.basics import *` below which is as seen in the cell block below.\n",
    "\n",
    "RELUs are simple linear equation algorithms that uses Gradient Descent for optimizations. And that is what we are going to be doing exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7721977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from fastai.basics import *\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c14c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import our dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f936c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0.000000\n",
       "Survived       0.000000\n",
       "Pclass         0.000000\n",
       "Name           0.000000\n",
       "Sex            0.000000\n",
       "Age            0.198653\n",
       "SibSp          0.000000\n",
       "Parch          0.000000\n",
       "Ticket         0.000000\n",
       "Fare           0.000000\n",
       "Cabin          0.771044\n",
       "Embarked       0.002245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform some necessary cleaning, transformation and feature engineering\n",
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6664b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete cabin and PassengerId in dataset, drop null values of Age and Embarked columns\n",
    "df.drop(columns = [\"PassengerId\", \"Cabin\"], inplace = True)\n",
    "#df.dropna(inplace=True)\n",
    "df['Age'].fillna(df[\"Age\"].mode()[0], inplace=True)\n",
    "df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f02dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete cabin colums -- High Cardinality\n",
    "df.drop(columns = \"Name\", inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e32cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete cabin colums  ---High cardinality\n",
    "df.drop(columns = \"Ticket\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2736515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0.0\n",
       "Pclass      0.0\n",
       "Sex         0.0\n",
       "Age         0.0\n",
       "SibSp       0.0\n",
       "Parch       0.0\n",
       "Fare        0.0\n",
       "Embarked    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456c1642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male  22.0      1      0   7.2500        S\n",
       "1         1       1  female  38.0      1      0  71.2833        C\n",
       "2         1       3  female  26.0      0      0   7.9250        S\n",
       "3         1       1  female  35.0      1      0  53.1000        S\n",
       "4         0       3    male  35.0      0      0   8.0500        S"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d477ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add dummy feature that will be used in the RELU matrx multiplication function\n",
    "dummy_list = [1] * len(df)\n",
    "df[\"dummy\"] = dummy_list\n",
    "df['dummy'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "266426ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  dummy\n",
       "0         0       3    male  22.0      1      0   7.2500        S      1\n",
       "1         1       1  female  38.0      1      0  71.2833        C      1\n",
       "2         1       3  female  26.0      0      0   7.9250        S      1\n",
       "3         1       1  female  35.0      1      0  53.1000        S      1\n",
       "4         0       3    male  35.0      0      0   8.0500        S      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c07cb1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\"Survived\", axis = 1).shape   ##Shape of dataset without target that is going into transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d0872",
   "metadata": {},
   "source": [
    "Perform transformations such as standard scaler, and OneHotEncoding on categorical data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a90ec50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    1\n",
       "2    3\n",
       "3    1\n",
       "4    3\n",
       "Name: Pclass, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First convert PClass to an object feature\n",
    "\n",
    "df[\"Pclass\"] = df[\"Pclass\"].astype(str)\n",
    "df[\"Pclass\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fddf685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.90258736, -0.56568542, -0.51015154, ..., -0.48204268,\n",
       "        -0.30756234,  1.        ],\n",
       "       [-1.10792599,  1.76776695, -0.51015154, ...,  2.0745051 ,\n",
       "        -0.30756234,  1.        ],\n",
       "       [ 0.90258736, -0.56568542, -0.51015154, ..., -0.48204268,\n",
       "        -0.30756234,  1.        ],\n",
       "       ...,\n",
       "       [ 0.90258736, -0.56568542, -0.51015154, ..., -0.48204268,\n",
       "        -0.30756234,  1.        ],\n",
       "       [-1.10792599,  1.76776695, -0.51015154, ...,  2.0745051 ,\n",
       "        -0.30756234,  1.        ],\n",
       "       [ 0.90258736, -0.56568542, -0.51015154, ..., -0.48204268,\n",
       "         3.25137334,  1.        ]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"Survived\"\n",
    "Xt = df.drop(columns = [\"dummy\", target]) #Initiate Xt, transformed that will be used for matrix multiplication,\n",
    "                                          #Drop dummy and target column, to avoid target and dummy getting transformed  \n",
    "\n",
    "transform_pipe = make_pipeline(OneHotEncoder(), #Transformation initialized in a pipeline\n",
    "                          StandardScaler())\n",
    "\n",
    "Xt = transform_pipe.fit_transform(Xt)         #Transformer piplien object made and called on the Xt dataset\n",
    "\n",
    "dm_array = np.array(df[\"dummy\"])[:, None]     #Create dummy array of the dummy column to be added back to the Xt to 2D\n",
    "\n",
    "Xt = np.concatenate([Xt, dm_array], axis = 1)  #Concatenate dummy array into Xt\n",
    "Xt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "424e962b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a11d5c",
   "metadata": {},
   "source": [
    "From the above we see that we arrived at a dataset of 712 rows and 13 columns, which is because of the category encoders, Lets us see below the columns that have been created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27711cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_1', 'Sex_2', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_1', 'Embarked_2', 'Embarked_3']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(transform_pipe.named_steps[\"onehotencoder\"].get_feature_names())\n",
    "print(len(transform_pipe.named_steps[\"onehotencoder\"].get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c2ed9af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(df[target])[:, None]\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466f451d",
   "metadata": {},
   "source": [
    "Since the dummy variable was not part of the features that went through the transformation pipeline, thus the length of the features generated by the transformer pipeline was 12 columns and plus 1(dummy feature) added manually by concatenation to make the final 13 columns that was generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6ae2c",
   "metadata": {},
   "source": [
    "The next step is to instantiate a tensor of random values that will be the paramenters of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "023c4646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initiate random seed\n",
    "np.random.seed(42)\n",
    "parameters = (np.random.random(13*1) - 0.5)[:, None]\n",
    "parameters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eaf3bc",
   "metadata": {},
   "source": [
    "Parameters that have been generated are random and are not responsive to a loss function yet until we put it into a tensor that does that. So the next step will involve using tensors and not numpy arrays to adjust the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94dfa0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert parameters to tensor object\n",
    "parameters_t = torch.tensor(parameters)\n",
    "parameters_t = parameters_t.float() #Convert to float cos of tensor calc\n",
    "#Also convert y array into tensor\n",
    "y_t = torch.tensor(y)\n",
    "y_t = y_t.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f913b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First let us define our loss function that our tensor of parameters will be adjusted by\n",
    "# def mae(acts, preds): \n",
    "#     return (torch.abs(preds - acts)).mean() #Convert prediction to sigmoid prediction\n",
    "\n",
    "# #Also define function that makes prediction using tensor parameters and clipping values of y (A RELU function)\n",
    "# def tensor_prediction(params):\n",
    "#     result = torch.matmul(torch.tensor(Xt), params)\n",
    "#     return torch.clip(result, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eda016f",
   "metadata": {},
   "source": [
    "In order to use a dataloader for training our model in batches, let us zip the training and prediction values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "eef6242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Xt to tensor\n",
    "X_t = tensor(Xt)\n",
    "X_t = X_t.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0ba6c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([13]), torch.Size([1]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(X_t, y_t))\n",
    "x,y = dset[0]\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2f395186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "#Split dataset into valid and train\n",
    "train_dset = dset[:700]\n",
    "valid_dset = dset[700:]\n",
    "\n",
    "#Test if sum of lengths equal to 891\n",
    "print(len(train_dset) + len(valid_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f32a8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_loss(preds, acts):\n",
    "    preds = preds.sigmoid()\n",
    "    return torch.where(acts==1, 1-preds, preds).mean().float()\n",
    "\n",
    "#Also define function that makes prediction using datasets\n",
    "#Since we will be using dataloaders, using dataset as input is\n",
    "#better than using parameteer\n",
    "def tensor_prediction(tensor_data):\n",
    "    tensor_data = tensor_data\n",
    "    #result = torch.matmul(torch.tensor(Xt), params)\n",
    "    result = tensor_data@parameters_t\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65147d3b",
   "metadata": {},
   "source": [
    "Using the sigmoid function and the corresponding loss function as opposed to the former loss function.\n",
    "\n",
    "The sigmoid function helps to create a function that gradually smoothens out the loss function output as the parameters change a little bit (Gradient Descent). The sigmoid function uses a formula as seen in this [wiki page](https://en.wikipedia.org/wiki/Sigmoid_function).\n",
    "\n",
    "It takes in the raw predictions made from the parameters and convert their predictions to be between 0 and 1 as a continous value. Note: No negative values or values above 1.\n",
    "\n",
    "The torch.where that accompanies the loss function works to penalize errors that are made when it makes prediction using the ffg ways:\n",
    "1. We are comparing each prediction and corresponding actual values.\n",
    "2. When the actual is 1, we return 1 minus the prediction made. This will have the following effect:\n",
    ">- When the prediction is close to 1, e.g., 0.9. The returned loss will be very small or zero if the prediction itself is 1\n",
    ">- If the prediction is not close to 1 however, the loss returned will be large. E.g 0.1 will return loss of 0.9\n",
    "3. When the actual is 0, we return the prediction made. This will have the following effect:\n",
    ">- When the prediction is close to 1, e.g., 0.9. The returned loss will be very large because it is confident that it is close to 1 whereas the actual is 0\n",
    ">- When the prediction is close to 0, The returned loss will be very small or zero if the prediction itself is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b5686c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5336)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us calculate the mae from the first random initial parameters that was generated\n",
    "\n",
    "sigmoid_loss(tensor_prediction(X_t), y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed298f2c",
   "metadata": {},
   "source": [
    "From the above we see the sigmoid being so high, so next we will initiate the adjustable torch parameters that will be adjusted based on gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a987626c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1255],\n",
       "        [ 0.4507],\n",
       "        [ 0.2320],\n",
       "        [ 0.0987],\n",
       "        [-0.3440],\n",
       "        [-0.3440],\n",
       "        [-0.4419],\n",
       "        [ 0.3662],\n",
       "        [ 0.1011],\n",
       "        [ 0.2081],\n",
       "        [-0.4794],\n",
       "        [ 0.4699],\n",
       "        [ 0.3324]], requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initiate requires_grad with the torch method for the parameters\n",
    "parameters_t.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebfc5d5",
   "metadata": {},
   "source": [
    "In order to begin training our data sets, we will do it batch by batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "369d722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(train_dset)\n",
    "valid_dl = DataLoader(valid_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e80b3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function that takes returns the loss and takes the loss backward\n",
    "\n",
    "def calc_grad(xb, yb, model):\n",
    "    pred = model(xb)\n",
    "    #Take the loss\n",
    "    loss = sigmoid_loss(pred, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9bc77024",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function that train each batch and that adjusts the parameters\n",
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        with torch.no_grad(): params -= params.grad*lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf2992c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the mae_loss function into a variable that calculates the loss based on the adjustable parameters\n",
    "#Test on the initial parameters seleced to see function is running properly --It should return\n",
    "#same loss as above --0.6577\n",
    "\n",
    "# loss = mae_loss(parameters_t)\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a645b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive the gradient of each parameters\n",
    "#each parameter has a partial derivative with respect to the loss function chosen\n",
    "#This is what is printed out as their gradients below\n",
    "# loss.backward()   #This method initiates the grad attribute that will be needed to checked\n",
    "# parameters_t.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf8925ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define accuracy function that takes accuracy of the valid_dl with eacch adjusted paramter\n",
    "#xb is the result from tensor_prediction of xbatch of valid_dl\n",
    "#yb is the actual from ybatch of valid_dl\n",
    "def batch_accuracy(xb, yb):\n",
    "    xb = xb.sigmoid()\n",
    "    correct = ((xb > 0.5) == yb).float()\n",
    "    return correct.mean()\n",
    "\n",
    "def valid_accuracy(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb, yb in valid_dl]\n",
    "    accs = round(torch.stack(accs).mean().item(), 4)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9c046",
   "metadata": {},
   "source": [
    "From the gradients displayed from the information above, we see that some parameters do have a negative gradient and with increase in their values, they would tend to get to the minimum values and lower the loss. The opposite is true for the positve gradients. Because in order to reduce the loss, we need a minima (gradient) values (close to zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1363c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define metrics for eye judgement\n",
    "# def acc1RELU(params):\n",
    "#     pred = tensor_prediction(params)\n",
    "#     preds = [1 if pre>0.5 else 0 for pre in pred]\n",
    "#     return accuracy_score(y_t, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "058ec698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Using gradient descent to perform the paramaters adjustment and print the accuracy for each epoch\n",
    "\n",
    "# for i in range(30):\n",
    "#     loss = mae_loss(parameters_t)\n",
    "#     loss.backward()\n",
    "#     with torch.no_grad(): parameters_t -= parameters_t.grad*0.01\n",
    "#     accuracy = acc1RELU(parameters_t)\n",
    "#     print(f'epoch={i}; accuracy={accuracy: .2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0a8f3ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0; accuracy=0.801\n",
      "epoch=1; accuracy=0.801\n",
      "epoch=2; accuracy=0.801\n",
      "epoch=3; accuracy=0.801\n",
      "epoch=4; accuracy=0.801\n",
      "epoch=5; accuracy=0.801\n",
      "epoch=6; accuracy=0.801\n",
      "epoch=7; accuracy=0.801\n",
      "epoch=8; accuracy=0.801\n",
      "epoch=9; accuracy=0.801\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train_epoch(tensor_prediction, 0.01, parameters_t)\n",
    "    accuracy = valid_accuracy(tensor_prediction)\n",
    "    print(f'epoch={i}; accuracy={accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc5b77",
   "metadata": {},
   "source": [
    "The parameters have been adjusted up to an optimal value (based on the range of values we chose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "00acbe2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -148.0764],\n",
       "        [  -24.4566],\n",
       "        [  208.4151],\n",
       "        [-1730.8922],\n",
       "        [ 1730.6466],\n",
       "        [ -223.9242],\n",
       "        [ -620.9936],\n",
       "        [  313.7205],\n",
       "        [ -235.7989],\n",
       "        [ -164.8757],\n",
       "        [   -4.5441],\n",
       "        [  268.5114],\n",
       "        [ -731.7578]], requires_grad=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With this change above, let us see the final parameters\n",
    "parameters_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6fa2a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.79\n"
     ]
    }
   ],
   "source": [
    "#Let us use this value to make predictions and check the accuracy_score of our prediction\n",
    "y_pred = tensor_prediction(X_t)\n",
    "y_pred = [1 if pred>0.5 else 0 for pred in y_pred]\n",
    "print(f\"Accuracy score: {accuracy_score(y_t, y_pred).round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cfa49d",
   "metadata": {},
   "source": [
    "This above is valid and used for creating a one layer RELUnet. In order to create a double layer RELUnet function, some tweaks with the ready made materials made from above will be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d20ba848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create param1 and param2 which will adjustable parameters\n",
    "\n",
    "# param1 = torch.tensor((np.random.random(13*1) - 0.5)[:, None])\n",
    "# param2 = torch.tensor((np.random.random(13*1) - 0.5)[:, None])\n",
    "# #param1.requires_grad_()\n",
    "# #param2.requires_grad_()\n",
    "# print(param1, param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0101713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grand_params = torch.hstack([param1, param2])\n",
    "# grand_params.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f3cd72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "#                 loss_func=sigmoid_loss, metrics=batch_accuracy)\n",
    "\n",
    "#To construct a simple 1 layer neural net, this code will do summarily all that we did before this code--\n",
    "#With its .fit(no_of_epochs, lr) method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abea9dd0",
   "metadata": {},
   "source": [
    "Using custom made classes and functions from FastAi and pytorch to create a two layer RELU net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7ca72686",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct dataloaders\n",
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1b377565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing double layer neural net\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(13, 6),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(6, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0d4d3b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.39646580815315247, 0.38594138622283936, 0.7015706896781921, '00:03']\n",
      "[1, 0.29197683930397034, 0.282769113779068, 0.8167539238929749, '00:02']\n",
      "[2, 0.24068117141723633, 0.22123922407627106, 0.8272251486778259, '00:02']\n",
      "[3, 0.21912850439548492, 0.1993936002254486, 0.8324607610702515, '00:02']\n",
      "[4, 0.21071785688400269, 0.19100947678089142, 0.8376963138580322, '00:02']\n",
      "[5, 0.20730893313884735, 0.18663519620895386, 0.8272251486778259, '00:02']\n",
      "[6, 0.20532594621181488, 0.18374621868133545, 0.8219895362854004, '00:02']\n",
      "[7, 0.20394663512706757, 0.18186412751674652, 0.8272251486778259, '00:04']\n",
      "[8, 0.203352689743042, 0.18056704103946686, 0.8324607610702515, '00:02']\n",
      "[9, 0.20296187698841095, 0.17956002056598663, 0.8324607610702515, '00:03']\n",
      "[10, 0.20256441831588745, 0.17876222729682922, 0.8324607610702515, '00:03']\n",
      "[11, 0.20217667520046234, 0.17811216413974762, 0.8324607610702515, '00:02']\n",
      "[12, 0.20192135870456696, 0.17761307954788208, 0.8324607610702515, '00:03']\n",
      "[13, 0.20159770548343658, 0.1772083193063736, 0.8324607610702515, '00:03']\n",
      "[14, 0.2013012021780014, 0.17684726417064667, 0.8324607610702515, '00:03']\n",
      "[15, 0.2011377215385437, 0.17655222117900848, 0.8324607610702515, '00:03']\n",
      "[16, 0.20087052881717682, 0.1762971729040146, 0.8324607610702515, '00:03']\n",
      "[17, 0.20062661170959473, 0.17604614794254303, 0.8324607610702515, '00:02']\n",
      "[18, 0.20043553411960602, 0.17584893107414246, 0.8324607610702515, '00:03']\n",
      "[19, 0.20022132992744446, 0.17563122510910034, 0.8324607610702515, '00:02']\n",
      "[20, 0.20006594061851501, 0.17546872794628143, 0.8324607610702515, '00:02']\n",
      "[21, 0.1998499631881714, 0.17528486251831055, 0.8324607610702515, '00:02']\n",
      "[22, 0.19966170191764832, 0.17512474954128265, 0.8324607610702515, '00:02']\n",
      "[23, 0.19954027235507965, 0.17496420443058014, 0.8324607610702515, '00:02']\n",
      "[24, 0.19933320581912994, 0.17481178045272827, 0.8324607610702515, '00:03']\n",
      "[25, 0.19921459257602692, 0.1746537834405899, 0.8324607610702515, '00:02']\n",
      "[26, 0.1989990919828415, 0.1745080202817917, 0.8324607610702515, '00:03']\n",
      "[27, 0.1988908350467682, 0.1743614375591278, 0.8324607610702515, '00:03']\n",
      "[28, 0.19867856800556183, 0.17420010268688202, 0.8324607610702515, '00:02']\n",
      "[29, 0.1985725611448288, 0.17408211529254913, 0.8324607610702515, '00:03']\n",
      "[30, 0.19828443229198456, 0.17392291128635406, 0.8324607610702515, '00:02']\n",
      "[31, 0.19823190569877625, 0.17380625009536743, 0.8324607610702515, '00:03']\n",
      "[32, 0.1980380117893219, 0.1736474335193634, 0.8324607610702515, '00:04']\n",
      "[33, 0.1979462206363678, 0.17353686690330505, 0.8324607610702515, '00:02']\n",
      "[34, 0.19775888323783875, 0.17340928316116333, 0.8324607610702515, '00:02']\n",
      "[35, 0.19755612313747406, 0.17327037453651428, 0.8376963138580322, '00:02']\n",
      "[36, 0.19746769964694977, 0.17313601076602936, 0.8376963138580322, '00:02']\n",
      "[37, 0.1973932385444641, 0.17301978170871735, 0.8376963138580322, '00:02']\n",
      "[38, 0.19720706343650818, 0.17286686599254608, 0.8376963138580322, '00:02']\n",
      "[39, 0.19714170694351196, 0.17273308336734772, 0.8376963138580322, '00:02']\n"
     ]
    }
   ],
   "source": [
    "#Create model architecture\n",
    "learn = Learner(dls, simple_net, opt_func=SGD, \n",
    "               loss_func=sigmoid_loss, metrics=batch_accuracy)\n",
    "learn.fit(40, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6bea7bce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.396466</td>\n",
       "      <td>0.385941</td>\n",
       "      <td>0.701571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291977</td>\n",
       "      <td>0.282769</td>\n",
       "      <td>0.816754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.240681</td>\n",
       "      <td>0.221239</td>\n",
       "      <td>0.827225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219129</td>\n",
       "      <td>0.199394</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210718</td>\n",
       "      <td>0.191009</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.207309</td>\n",
       "      <td>0.186635</td>\n",
       "      <td>0.827225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.205326</td>\n",
       "      <td>0.183746</td>\n",
       "      <td>0.821990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203947</td>\n",
       "      <td>0.181864</td>\n",
       "      <td>0.827225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.203353</td>\n",
       "      <td>0.180567</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.202962</td>\n",
       "      <td>0.179560</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.202564</td>\n",
       "      <td>0.178762</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.202177</td>\n",
       "      <td>0.178112</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.201921</td>\n",
       "      <td>0.177613</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.201598</td>\n",
       "      <td>0.177208</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.201301</td>\n",
       "      <td>0.176847</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.201138</td>\n",
       "      <td>0.176552</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.200871</td>\n",
       "      <td>0.176297</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.200627</td>\n",
       "      <td>0.176046</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.200436</td>\n",
       "      <td>0.175849</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.200221</td>\n",
       "      <td>0.175631</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.200066</td>\n",
       "      <td>0.175469</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.199850</td>\n",
       "      <td>0.175285</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.199662</td>\n",
       "      <td>0.175125</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.199540</td>\n",
       "      <td>0.174964</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.199333</td>\n",
       "      <td>0.174812</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.199215</td>\n",
       "      <td>0.174654</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.198999</td>\n",
       "      <td>0.174508</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.198891</td>\n",
       "      <td>0.174361</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.198679</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.198573</td>\n",
       "      <td>0.174082</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.198284</td>\n",
       "      <td>0.173923</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.198232</td>\n",
       "      <td>0.173806</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.198038</td>\n",
       "      <td>0.173647</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.197946</td>\n",
       "      <td>0.173537</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.197759</td>\n",
       "      <td>0.173409</td>\n",
       "      <td>0.832461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.197556</td>\n",
       "      <td>0.173270</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.197468</td>\n",
       "      <td>0.173136</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.197393</td>\n",
       "      <td>0.173020</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.197207</td>\n",
       "      <td>0.172867</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.197142</td>\n",
       "      <td>0.172733</td>\n",
       "      <td>0.837696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_loss  batch_accuracy\n",
       "0     0.396466    0.385941        0.701571\n",
       "1     0.291977    0.282769        0.816754\n",
       "2     0.240681    0.221239        0.827225\n",
       "3     0.219129    0.199394        0.832461\n",
       "4     0.210718    0.191009        0.837696\n",
       "5     0.207309    0.186635        0.827225\n",
       "6     0.205326    0.183746        0.821990\n",
       "7     0.203947    0.181864        0.827225\n",
       "8     0.203353    0.180567        0.832461\n",
       "9     0.202962    0.179560        0.832461\n",
       "10    0.202564    0.178762        0.832461\n",
       "11    0.202177    0.178112        0.832461\n",
       "12    0.201921    0.177613        0.832461\n",
       "13    0.201598    0.177208        0.832461\n",
       "14    0.201301    0.176847        0.832461\n",
       "15    0.201138    0.176552        0.832461\n",
       "16    0.200871    0.176297        0.832461\n",
       "17    0.200627    0.176046        0.832461\n",
       "18    0.200436    0.175849        0.832461\n",
       "19    0.200221    0.175631        0.832461\n",
       "20    0.200066    0.175469        0.832461\n",
       "21    0.199850    0.175285        0.832461\n",
       "22    0.199662    0.175125        0.832461\n",
       "23    0.199540    0.174964        0.832461\n",
       "24    0.199333    0.174812        0.832461\n",
       "25    0.199215    0.174654        0.832461\n",
       "26    0.198999    0.174508        0.832461\n",
       "27    0.198891    0.174361        0.832461\n",
       "28    0.198679    0.174200        0.832461\n",
       "29    0.198573    0.174082        0.832461\n",
       "30    0.198284    0.173923        0.832461\n",
       "31    0.198232    0.173806        0.832461\n",
       "32    0.198038    0.173647        0.832461\n",
       "33    0.197946    0.173537        0.832461\n",
       "34    0.197759    0.173409        0.832461\n",
       "35    0.197556    0.173270        0.837696\n",
       "36    0.197468    0.173136        0.837696\n",
       "37    0.197393    0.173020        0.837696\n",
       "38    0.197207    0.172867        0.837696\n",
       "39    0.197142    0.172733        0.837696"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"train_loss\", \"valid_loss\", \"batch_accuracy\"]\n",
    "values = learn.recorder.values\n",
    "\n",
    "pd.DataFrame(values, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "913e7ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double RELU function that takes advantage of the matrix multpilication\n",
    "# def grand_pred(params):\n",
    "#     result = torch.matmul(torch.tensor(Xt), params)\n",
    "#     #result = torch.clip(result, 0.)\n",
    "#     result = result[:,0] + result[:,1]\n",
    "#     result = result.sigmoid()\n",
    "#     return result[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "afb4b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define mae_loss\n",
    "# def grand_mae_loss(params):\n",
    "#     return mae(y_t, grand_pred(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "064b716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grand_loss = grand_mae_loss(grand_params)\n",
    "# grand_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "1d883347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grand_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "555d75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the gradient of each \n",
    "# grand_params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "694e62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define loss function for RELU2net\n",
    "\n",
    "# def acc2RELU(params):\n",
    "#     pred = grand_pred(params)\n",
    "#     preds = [1 if pre>0.5 else 0 for pre in pred]\n",
    "#     return accuracy_score(y_t, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "95548538",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take loop through the gadient descent\n",
    "# for i in range(30):\n",
    "#     grand_loss = grand_mae_loss(grand_params)\n",
    "#     grand_loss.backward()\n",
    "#     with torch.no_grad(): grand_params -= grand_params.grad*0.01\n",
    "#     accuracy2 = acc2RELU(grand_params)\n",
    "#     print(f'epoch={i+1}; accuracy={accuracy2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d1154fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #What is the final grand parameter\n",
    "# grand_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "26fbf4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us use this value to make predictions and check the accuracy_score of our prediction\n",
    "# y_pred = grand_pred(grand_params)\n",
    "# y_pred = [1 if pred>0.5 else 0 for pred in y_pred]\n",
    "# print(f\"Accuracy score: {accuracy_score(y_t, y_pred).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "45b89385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple naive model wil have an accuracy of 0.6162\n"
     ]
    }
   ],
   "source": [
    "naive_model=round(df[\"Survived\"].value_counts(normalize=True).max(), 4)\n",
    "print(f\"A simple naive model wil have an accuracy of {naive_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b747b2",
   "metadata": {},
   "source": [
    "From this, we see that the RELUnet that we made does far well than a simlple and naive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45948023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trying both model on the test set\n",
    "#first define wrangle function\n",
    "\n",
    "def wrangle(filepath):\n",
    "    \n",
    "    #Read in filepath\n",
    "    data = pd.read_csv(filepath)\n",
    "    #Obtain dataindex\n",
    "    data_index = data[\"PassengerId\"]\n",
    "    \n",
    "    #Drop the following stated columns\n",
    "    data.drop(columns = [\"PassengerId\", \"Cabin\", \"Name\", \"Ticket\"], inplace = True)\n",
    "    \n",
    "    #Fill missing values\n",
    "    data[\"Age\"].fillna(data[\"Age\"].mode()[0], inplace=True)\n",
    "    data[\"Fare\"].fillna(data[\"Fare\"].mean(), inplace=True)\n",
    "    #Convert the Pclass column to string type\n",
    "    data[\"Pclass\"] = data[\"Pclass\"].astype(str)\n",
    "    \n",
    "    #create dummy\n",
    "    dummy = [1] * len(data)\n",
    "    \n",
    "    #Add transformation to the dataset\n",
    "    train_trans = transform_pipe.fit_transform(data)        \n",
    "    \n",
    "    #Concatenate dummy array into train_trans\n",
    "    dummy_array = np.array(dummy)[:, None]     \n",
    "    train_trans = np.concatenate([train_trans, dummy_array], axis = 1)  \n",
    "    return train_trans, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7f7e3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train, idx = wrangle(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "baaca1eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 13)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b0403f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_data(data, model_parameters):\n",
    "    result = torch.matmul(torch.tensor(data), model_parameters)\n",
    "    result = torch.clip(result, 0.)\n",
    "    if model_parameters.shape[1] > 1:\n",
    "        result = result[:,0] + result[:,1]\n",
    "        return result[:,None]\n",
    "    return result[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4afb3395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e15c3533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "RELU1_pred = pred_data(test_train, parameters_t)\n",
    "RELU1_pred = [1 if pred>0.5 else 0 for pred in RELU1_pred]\n",
    "print(RELU1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b05958a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "RELU2_pred = pred_data(test_train, grand_params)\n",
    "RELU2_pred = [1 if pred>0.5 else 0 for pred in RELU2_pred]\n",
    "print(RELU2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5b74312b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(RELU2_pred, index=idx).rename(\"prediction\").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "448eed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pd.Series(RELU1_pred, index=idx).rename(\"prediction\").to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6a410628",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fe577305",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.rename(columns={\"index\": \"PassengerId\", \"prediction\":\"Survived\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bac0198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(\"RELU20121prediction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715e18ac",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "- The whole process can be more flexible than many hardcodcoding done in this notebook. I only did this as a form of practical learning and trying my hands on what I was taught. A suitable way to go about this might be encapsulate it all as a class\n",
    "\n",
    "- A double RELUnet will possibly take more time(epochs) to train than a single RELUnet, thus on a more refined model construction, the double RELUnet model should do better than the single net model. ## It now does. Check READme for reason why it was not performing as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e819f",
   "metadata": {},
   "source": [
    "## Image of entry into the titanic dataset competition with self built RELU network\n",
    "\n",
    "![image](Images/kaggle.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
